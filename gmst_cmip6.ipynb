{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gcsfs\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import intake\n",
    "import xesmf as xe\n",
    "%matplotlib inline\n",
    "import cartopy\n",
    "from cartopy import util\n",
    "import cartopy.crs as ccrs\n",
    "import zarr\n",
    "import dask.array as da  \n",
    "from dask.diagnostics import ProgressBar\n",
    "from tqdm.autonotebook import tqdm\n",
    "import nc_time_axis\n",
    "import time\n",
    "\n",
    "import cmip6_preprocessing\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_url = \"/space/hall4/sitestore/eccc/crd/CMIP6/final/canesm_final.json\"\n",
    "cat_url = \"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\"\n",
    "col = intake.open_esm_datastore(cat_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix some inconsistencies across datasets like dimension names, bounds, extra variables, etc.\n",
    "from cmip6_preprocessing.preprocessing import combined_preprocessing, replace_x_y_nominal_lat_lon, rename_cmip6\n",
    "\n",
    "def wrapper(ds):\n",
    "    ds = ds.copy()\n",
    "    #ds = rename_cmip6(ds)\n",
    "    #ds = replace_x_y_nominal_lat_lon(ds)\n",
    "    \n",
    "    if ('longitude' in ds.dims) and ('latitude' in ds.dims):\n",
    "        ds = ds.rename({'longitude':'lon', 'latitude': 'lat'}) # some models labelled dimensions differently...\n",
    "    if ('bnds' in ds.dims): \n",
    "        ds=ds.drop_dims('bnds')\n",
    "    if ('vertex' in ds.dims): \n",
    "        ds=ds.drop_dims('vertex')\n",
    "    if ('height' in ds.dims): \n",
    "        ds=ds.drop_dims('height')\n",
    "    if ('height' in ds): \n",
    "        ds=ds.drop_vars('height')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "                \n",
      "--> There is/are 34 group(s)\n",
      "[########################################] | 100% Completed |  2.4s\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "                \n",
      "--> There is/are 7 group(s)\n",
      "[########################################] | 100% Completed |  0.4s\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "                \n",
      "--> There is/are 23 group(s)\n",
      "[########################################] | 100% Completed |  1.3s\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "                \n",
      "--> There is/are 22 group(s)\n",
      "[########################################] | 100% Completed |  1.4s\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "                \n",
      "--> There is/are 22 group(s)\n",
      "[########################################] | 100% Completed |  1.3s\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "                \n",
      "--> There is/are 22 group(s)\n",
      "[########################################] | 100% Completed |  1.4s\n"
     ]
    }
   ],
   "source": [
    "dset_dicts={}\n",
    "experiment_ids=['historical', 'ssp119','ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "\n",
    "for exp in experiment_ids:\n",
    "    query = dict(table_id=['Amon'], \n",
    "                 variable_id=['tas'],\n",
    "              experiment_id=exp, member_id='r1i1p1f1')\n",
    "    cat = col.search(**query)\n",
    "    dset_dicts[exp] = cat.to_dataset_dict(zarr_kwargs={'consolidated': True}, \n",
    "                                        storage_options={'token': 'anon'}, \n",
    "                                        preprocess=wrapper,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids=['historical', 'ssp119','ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "dset_dicts_proc = {}\n",
    "\n",
    "for exp in experiment_ids:\n",
    "    tmp = {}\n",
    "    for name, data in dset_dicts[exp].items():\n",
    "        model = name.split('.')[2]\n",
    "        tmp[model] = data\n",
    "    dset_dicts_proc[exp] = tmp\n",
    "\n",
    "dset_dicts_match = {}\n",
    "dset_dicts_match['historical'] = dset_dicts_proc['historical']\n",
    "    \n",
    "experiment_ids=['ssp119','ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "for exp in experiment_ids:\n",
    "    tmp = {}\n",
    "    for name, data in dset_dicts_proc[exp].items():\n",
    "        if name in dset_dicts_proc['historical'].keys(): \n",
    "            tmp[name] = data\n",
    "    dset_dicts_match[exp] = tmp                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmst_dicts = {}\n",
    "#glob_area = areacella.sum(dim=['lon', 'lat'])\n",
    "for exp, dic in dset_dicts_match.items():\n",
    "    tmp = {}\n",
    "    for model, data in dic.items():\n",
    "        cos_lat_2d = np.cos(np.deg2rad(data['lat'])) * xr.ones_like(data['lon'])\n",
    "        tmp[model] = ((data * cos_lat_2d).sum(dim=['lon', 'lat'])/cos_lat_2d.sum(dim=['lat','lon'])).compute()\n",
    "    gmst_dicts[exp] = tmp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmst_anom_dicts = {}\n",
    "#glob_area = areacella.sum(dim=['lon', 'lat'])\n",
    "for exp, dic in gmst_dicts.items():\n",
    "    tmp = {}\n",
    "    for model, data in dic.items():\n",
    "        try:\n",
    "            tmp[model] = (data.sel(time=slice('1850','2100')) - \n",
    "                          gmst_dicts['historical'][model].sel(time=slice('1850','1900')).mean(dim='time')\n",
    "                         ).groupby('time.year').mean(dim='time').compute()\n",
    "        except:\n",
    "            print('Failed:', model)\n",
    "    gmst_anom_dicts[exp] = tmp   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmst_anoms = {}\n",
    "#glob_area = areacella.sum(dim=['lon', 'lat'])\n",
    "for exp, dic in gmst_anom_dicts.items():\n",
    "    dss = [ds for key, ds in dic.items()]\n",
    "    gmst_anoms[exp] = xr.concat(dss, dim='source_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download obs from my FTP.\n",
    "! wget ftp://crd-data-donnees-rdc.ec.gc.ca/pub/CCCMA/nswart/fldmean_NASA-GISS_gistemp1200_GHCNv4_ERSSTv5.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = xr.open_dataset('fldmean_NASA-GISS_gistemp1200_GHCNv4_ERSSTv5.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_anom = (obs - obs.sel(time=slice('1850','1900')).mean(dim='time')).groupby('time.year').mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bounds = {}\n",
    "lower_bounds = {}\n",
    "for key, data in gmst_anoms.items():\n",
    "    upper_bounds[key] = (data['tas'].mean(dim='source_id') + \n",
    "                         data['tas'].std(dim='source_id')*2.0).squeeze()#/np.sqrt(len(data['tas'].member_id)))\n",
    "    lower_bounds[key] = (data['tas'].mean(dim='source_id') -\n",
    "                         data['tas'].std(dim='source_id')*2.0).squeeze()#/np.sqrt(len(data['tas'].member_id))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(6,4))\n",
    "\n",
    "colors = ['k', 'tab:cyan', 'tab:blue', 'darkorange', 'tab:red']\n",
    "label = ['historical', 'SSP1-26', 'SSP2-45', 'SSP3-70', 'SSP5-85']\n",
    "for i, key in enumerate(['historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']):\n",
    "    ax.fill_between(gmst_anoms[key].year, upper_bounds[key], lower_bounds[key], \n",
    "                    facecolor=colors[i], alpha=0.3)\n",
    "\n",
    "    ax.plot(gmst_anoms[key].year, gmst_anoms[key]['tas'].mean(dim='source_id'), \n",
    "            color=colors[i], label=label[i])\n",
    "    \n",
    "ax.plot(obs_anom.year, obs_anom.tempanomaly.squeeze(), 'tab:pink', label='NASA-GISS obs.')\n",
    "ax.legend(frameon=False, loc='upper left')\n",
    "ax.set_ylabel('GMST anomaly ($^{\\circ}$C)')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_xlim([1850, 2100])\n",
    "ax.text(2020,-2.5, '@neil_c_swart / CCCma', alpha=0.5)\n",
    "\n",
    "ax.set_title('CMIP6 mean anomalies relative to 1850-1900')\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.5))\n",
    "ax.tick_params(axis='both', left=True, right=True, which='both', direction='in')\n",
    "fig.savefig('CMIP6_GMST_anomalies_plus-obs.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
